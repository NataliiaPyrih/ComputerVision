{"cells":[{"source":"Pneumonia is one of the leading respiratory illnesses worldwide, and its timely and accurate diagnosis is essential for effective treatment. Manually reviewing chest X-rays is a critical step in this process, and AI can provide valuable support by helping to expedite the assessment. In your role as a consultant data scientist, you will test the ability of a deep learning model to distinguish pneumonia cases from normal images of lungs in chest X-rays.\n\nBy fine-tuning a pre-trained convolutional neural network, specifically the ResNet-18 model, your task is to classify X-ray images into two categories: normal lungs and those affected by pneumonia. You can leverage its already trained weights and get an accurate classifier trained faster and with fewer resources.\n\n## The Data\n\n<img src=\"x-rays_sample.png\" align=\"center\"/>\n&nbsp\n\nYou have a dataset of chest X-rays that have been preprocessed for use with a ResNet-18 model. You can see a sample of 5 images from each category above. Upon unzipping the `chestxrays.zip` file (code provided below), you will find your dataset inside the `data/chestxrays` folder divided into `test` and `train` folders. \n\nThere are 150 training images and 50 testing images for each category, NORMAL and PNEUMONIA (300 and 100 in total). For your convenience, this data has already been loaded into a `train_loader` and a `test_loader` using the `DataLoader` class from the PyTorch library. ","metadata":{},"id":"85dc467a-5830-44c0-ab74-435be0e5593c","cell_type":"markdown"},{"source":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","metadata":{"executionCancelledAt":null,"executionTime":3030,"lastExecutedAt":1738180371126,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# # Make sure to run this cell to use torchmetrics.\n!pip install torch torchvision torchmetrics","outputsMetadata":{"0":{"height":605,"type":"stream"}}},"id":"0f522b79-2a5a-4472-adb9-0d924870bfa1","cell_type":"code","execution_count":51,"outputs":[{"output_type":"stream","name":"stdout","text":"Defaulting to user installation because normal site-packages is not writeable\nRequirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.0)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.8/dist-packages (0.14.0)\nRequirement already satisfied: torchmetrics in /home/repl/.local/lib/python3.8/site-packages (1.5.2)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\nRequirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.8/dist-packages (from torch) (8.5.0.96)\nRequirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.8/dist-packages (from torch) (11.10.3.66)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.8/dist-packages (from torch) (11.7.99)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.6.3)\nRequirement already satisfied: wheel in /usr/local/lib/python3.8/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchvision) (1.23.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchvision) (2.31.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.8/dist-packages (from torchvision) (9.2.0)\nRequirement already satisfied: packaging>17.1 in /usr/local/lib/python3.8/dist-packages (from torchmetrics) (23.2)\nRequirement already satisfied: lightning-utilities>=0.8.0 in /home/repl/.local/lib/python3.8/site-packages (from torchmetrics) (0.11.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.8/dist-packages (from requests->torchvision) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision) (2.8)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/lib/python3/dist-packages (from requests->torchvision) (1.25.8)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision) (2019.11.28)\n\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0\u001b[0m\n\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"}]},{"source":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)","metadata":{"executionCancelledAt":null,"executionTime":50,"lastExecutedAt":1738180371178,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Import required libraries\n# -------------------------\n# Data loading\nimport random\nimport numpy as np\nfrom torchvision.transforms import transforms\nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import DataLoader\n\n# Train model\nimport torch\nfrom torchvision import models\nimport torch.nn as nn\nimport torch.optim as optim\n\n# Evaluate model\nfrom torchmetrics import Accuracy, F1Score\n\n# Set random seeds for reproducibility\ntorch.manual_seed(101010)\nnp.random.seed(101010)\nrandom.seed(101010)"},"id":"cb1bedee-bcd5-4c80-a5ed-93df89af0295","cell_type":"code","execution_count":52,"outputs":[]},{"source":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')","metadata":{"executionCancelledAt":null,"executionTime":47,"lastExecutedAt":1738180371225,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"import os\nimport zipfile\n\n# Unzip the data folder\nif not os.path.exists('data/chestxrays'):\n    with zipfile.ZipFile('data/chestxrays.zip', 'r') as zip_ref:\n        zip_ref.extractall('data')"},"id":"dd91680d-cb63-4876-9a51-4ee6bb250c7d","cell_type":"code","execution_count":53,"outputs":[]},{"source":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1738180371273,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"# Define the transformations to apply to the images for use with ResNet-18\ntransform_mean = [0.485, 0.456, 0.406]\ntransform_std =[0.229, 0.224, 0.225]\ntransform = transforms.Compose([transforms.ToTensor(), \n                                transforms.Normalize(mean=transform_mean, std=transform_std)])\n\n# Apply the image transforms\ntrain_dataset = ImageFolder('data/chestxrays/train', transform=transform)\ntest_dataset = ImageFolder('data/chestxrays/test', transform=transform)\n\n# Create data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=len(train_dataset) // 2, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=len(test_dataset))"},"id":"0cc5591a-8dc1-4d7f-88d2-3b1a59fb2a5f","cell_type":"code","execution_count":54,"outputs":[]},{"source":"resnet18 = models.resnet18(pretrained=True)\n\nfor param in resnet18.parameters():\n    param.requires_grad = False","metadata":{"executionCancelledAt":null,"executionTime":186,"lastExecutedAt":1738180371459,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"resnet18 = models.resnet18(pretrained=True)\n\nfor param in resnet18.parameters():\n    param.requires_grad = False","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"id":"c99cf95b-83f3-49e4-9777-4e70736452d8","cell_type":"code","execution_count":55,"outputs":[]},{"source":"num_features = resnet18.fc.in_features\nresnet18.fc = nn.Linear(num_features, 1)","metadata":{"executionCancelledAt":null,"executionTime":49,"lastExecutedAt":1738180371509,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"num_features = resnet18.fc.in_features\nresnet18.fc = nn.Linear(num_features, 1)"},"cell_type":"code","id":"f59478af-7acc-4030-b049-751d3a61d09f","outputs":[],"execution_count":56},{"source":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=0.001)","metadata":{"executionCancelledAt":null,"executionTime":55,"lastExecutedAt":1738180371565,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"criterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(resnet18.parameters(), lr=0.001)"},"cell_type":"code","id":"b7e8bc91-10c7-45e8-a112-0e105d78a369","outputs":[],"execution_count":57},{"source":"epochs = 3\nfor epoch in range(epochs):\n    resnet18.train()\n    running_loss = 0\n    for images, labels in train_loader:\n        labels = labels.float().unsqueeze(1)\n\n        optimizer.zero_grad()\n        outputs = resnet18(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item()\n\n    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastExecutedByKernel":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":80,"type":"stream"}}},"cell_type":"code","id":"098e3ea8-5942-4aca-873c-110064103d1e","outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/3, Loss: 0.6941\nEpoch 2/3, Loss: 0.6431\nEpoch 3/3, Loss: 0.6169\n"}],"execution_count":58},{"source":"### Below is the provided model evaluation code. Run the below cell to help you evaluate the accuracy and F1-score of your fine-tuned model.","metadata":{},"id":"70761893-e66f-40fe-8862-dac9b18a13ab","cell_type":"markdown"},{"source":"#-------------------\n# Evaluate the model\n#-------------------\n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_acc = accuracy_metric(all_preds, all_labels).item()\n    test_f1 = f1_metric(all_preds, all_labels).item()","metadata":{"executionCancelledAt":null,"executionTime":1809,"lastExecutedAt":1738180390372,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#-------------------\n# Evaluate the model\n#-------------------\n\n# Set model to evaluation mode\nmodel = resnet18\nmodel.eval()\n\n# Initialize metrics for accuracy and F1 score\naccuracy_metric = Accuracy(task=\"binary\")\nf1_metric = F1Score(task=\"binary\")\n\n# Create lists store all predictions and labels\nall_preds = []\nall_labels = []\n\n# Disable gradient calculation for evaluation\nwith torch.no_grad():\n  for inputs, labels in test_loader:\n    # Forward pass\n    outputs = model(inputs)\n    preds = torch.sigmoid(outputs).round()  # Round to 0 or 1\n\n    # Extend the lists with predictions and labels\n    all_preds.extend(preds.tolist())\n    all_labels.extend(labels.unsqueeze(1).tolist())\n\n    # Convert lists back to tensors\n    all_preds = torch.tensor(all_preds)\n    all_labels = torch.tensor(all_labels)\n\n    # Calculate accuracy and F1 score\n    test_acc = accuracy_metric(all_preds, all_labels).item()\n    test_f1 = f1_metric(all_preds, all_labels).item()"},"id":"7e0e1ad6-2f78-4a14-943b-8cc7c9dfe960","cell_type":"code","execution_count":59,"outputs":[]},{"source":"test_accuracy = round(test_acc, 3)\ntest_f1_score = round(test_f1, 3)","metadata":{"executionCancelledAt":null,"executionTime":52,"lastExecutedAt":1738180390425,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"test_accuracy = round(test_acc, 3)\ntest_f1_score = round(test_f1, 3)"},"cell_type":"code","id":"bef1fdb9-034f-46c5-a993-18375b719ee6","outputs":[],"execution_count":60},{"source":"print(f\"Test accuracy: {test_accuracy}\")\nprint(f\"Test accuracy: {test_f1_score}\")","metadata":{"executionCancelledAt":null,"executionTime":48,"lastExecutedAt":1738180390473,"lastExecutedByKernel":"36ab984c-f105-4923-b895-dc98883c10dc","lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"print(f\"Test accuracy: {test_accuracy}\")\nprint(f\"Test accuracy: {test_f1_score}\")","outputsMetadata":{"0":{"height":59,"type":"stream"}}},"cell_type":"code","id":"5304c581-64ab-4316-b512-82a4ded5b339","outputs":[{"output_type":"stream","name":"stdout","text":"Test accuracy: 0.55\nTest accuracy: 0.571\n"}],"execution_count":61}],"metadata":{"colab":{"name":"Welcome to DataCamp Workspaces.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataLab"},"nbformat":4,"nbformat_minor":5}